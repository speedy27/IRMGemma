const express = require('express');
const cors = require('cors');
const multer = require('multer');
const { v4: uuidv4 } = require('uuid');
require('dotenv').config();

const { PredictionServiceClient } = require('@google-cloud/aiplatform');
const { helpers } = require('@google-cloud/aiplatform');

const app = express();
const port = process.env.PORT || 3001;

// Middleware
app.use(cors());
app.use(express.json({ limit: '50mb' }));
app.use(express.urlencoded({ extended: true, limit: '50mb' }));

// Configuration pour Vertex AI
const projectId = process.env.GOOGLE_CLOUD_PROJECT_ID;
const location = process.env.GOOGLE_CLOUD_LOCATION || 'europe-west4';
const endpointId = process.env.MEDGEMMA_ENDPOINT_ID;
const modelId = process.env.MEDGEMMA_MODEL_ID || 'medgemma-2b';
const isDevelopmentMode = process.env.DEVELOPMENT_MODE === 'true';

// Initialiser le client Vertex AI pour endpoint d√©di√© (seulement si pas en mode dev)
let predictionServiceClient = null;
if (!isDevelopmentMode && process.env.GOOGLE_APPLICATION_CREDENTIALS) {
  try {
    predictionServiceClient = new PredictionServiceClient({
      apiEndpoint: `${location}-aiplatform.googleapis.com`,
    });
  } catch (error) {
    console.warn('‚ö†Ô∏è Impossible d\'initialiser le client Vertex AI:', error.message);
    console.log('üîß Mode d√©veloppement activ√© automatiquement');
  }
}

// Configuration Multer pour les images
const storage = multer.memoryStorage();
const upload = multer({ 
  storage: storage,
  limits: { fileSize: 50 * 1024 * 1024 } // 50MB limit
});

// Fonction pour encoder l'image en base64
function encodeImageToBase64(buffer, mimeType) {
  return `data:${mimeType};base64,${buffer.toString('base64')}`;
}

// Fonction pour cr√©er le prompt m√©dical structur√© pour MedGemma
function createMedicalPrompt(clinicalContext, hasImages) {
  const basePrompt = `Tu es MedGemma, un assistant IA m√©dical sp√©cialis√© dans l'analyse d'imagerie m√©dicale.

CONTEXTE CLINIQUE:
${clinicalContext || 'Aucun contexte clinique fourni.'}

${hasImages ? `
IMAGES M√âDICALES:
Tu vas analyser les images m√©dicales fournies ci-dessous.

INSTRUCTIONS D'ANALYSE:
1. Examine attentivement chaque image m√©dicale
2. Identifie les structures anatomiques visibles
3. Recherche les anomalies ou pathologies
4. Corr√®le avec le contexte clinique fourni
5. Propose un diagnostic diff√©rentiel
6. √âvalue le niveau de confiance de tes observations

ANALYSE DEMAND√âE:
- D√©cris les principales observations
- Identifie les zones d'int√©r√™t pathologiques
- Propose une hypoth√®se diagnostique principale
- Indique le niveau de confiance (0-100%)
- Sugg√®re des examens compl√©mentaires si n√©cessaire
- Formule des recommandations cliniques

FORMAT DE R√âPONSE:
R√©ponds de mani√®re structur√©e et professionnelle en tant que radiologue expert.
` : `
CONSULTATION SANS IMAGE:
Analyse le contexte clinique fourni et fournis des recommandations.
`}

R√âPONSE:`;

  return basePrompt;
}

// Route pour analyser les images avec MedGemma
app.post('/api/analyze', upload.array('images'), async (req, res) => {
  try {
    const { clinicalContext } = req.body;
    const images = req.files || [];

    console.log('D√©but de l\'analyse MedGemma...');
    console.log('Contexte clinique:', clinicalContext);
    console.log('Nombre d\'images:', images.length);
    console.log('Mode d√©veloppement:', isDevelopmentMode);

    // Si en mode d√©veloppement ou pas de client configur√©, retourner une analyse simul√©e
    if (isDevelopmentMode || !predictionServiceClient) {
      console.log('üîß Mode d√©veloppement - Analyse simul√©e');
      
      const mockAnalysis = {
        hypothesis: "Analyse simul√©e - Configuration MedGemma d√©tect√©e",
        confidence: 85,
        observations: [
          "Configuration MedGemma correcte (Project: 744112801898)",
          "Endpoint d√©di√© configur√© (ID: 7577009504911360000)",
          "R√©gion europe-west4 s√©lectionn√©e",
          images.length > 0 ? `${images.length} image(s) re√ßue(s) pour analyse` : "Aucune image fournie",
          clinicalContext ? "Contexte clinique fourni" : "Aucun contexte clinique"
        ],
        severity: "low",
        recommendations: [
          "Configurez votre cl√© de service Google Cloud pour l'analyse r√©elle",
          "Placez le fichier JSON de la cl√© dans le dossier Backend",
          "Mettez √† jour GOOGLE_APPLICATION_CREDENTIALS dans .env",
          "Retirez DEVELOPMENT_MODE=true pour activer MedGemma"
        ],
        fullReport: `SIMULATION MEDGEMMA - ${new Date().toISOString()}

CONFIGURATION D√âTECT√âE:
- Project ID: ${projectId}
- Region: ${location}
- Endpoint: ${endpointId}
- Model: ${modelId}

CONTEXTE CLINIQUE:
${clinicalContext || 'Aucun contexte fourni'}

IMAGES:
${images.length} image(s) upload√©e(s)

STATUS:
‚úÖ Configuration MedGemma correcte
‚ö†Ô∏è Mode d√©veloppement activ√©
üîë Cl√© de service requise pour analyse r√©elle

PROCHAINES √âTAPES:
1. T√©l√©chargez votre cl√© de service Google Cloud
2. Placez-la dans le dossier Backend
3. Mettez √† jour le chemin dans .env
4. D√©sactivez le mode d√©veloppement`
      };

      return res.json({ success: true, analysis: mockAnalysis });
    }

    // Code d'analyse r√©elle avec MedGemma...
    // Pr√©parer le prompt
    const prompt = createMedicalPrompt(clinicalContext, images.length > 0);

    // ...existing code...

    // Pr√©parer les contenus pour MedGemma
    const instances = [];
    
    // Format pour MedGemma avec endpoint d√©di√©
    const instance = {
      prompt: prompt,
      max_tokens: 2048,
      temperature: 0.1,
      top_p: 0.8
    };

    // Ajouter les images si pr√©sentes
    if (images.length > 0) {
      instance.images = images.map(image => ({
        mime_type: image.mimetype,
        data: image.buffer.toString('base64')
      }));
    }

    instances.push(instance);

    // Construire le chemin de l'endpoint d√©di√©
    const endpoint = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;

    const request = {
      endpoint,
      instances: instances.map(instance => helpers.toValue(instance)),
      parameters: helpers.toValue({})
    };

    console.log('Envoi de la requ√™te √† Vertex AI...');

    // Appel √† Vertex AI
    const [response] = await predictionServiceClient.predict(request);
    
    console.log('R√©ponse re√ßue de Vertex AI');

    // Traiter la r√©ponse de l'endpoint d√©di√© MedGemma
    const predictions = response.predictions;
    if (!predictions || predictions.length === 0) {
      throw new Error('Aucune pr√©diction re√ßue de MedGemma');
    }

    const prediction = predictions[0];
    let responseText;

    // Extraire le texte de la r√©ponse selon le format de MedGemma
    if (prediction.structValue) {
      // Format structur√©
      const fields = prediction.structValue.fields;
      responseText = fields?.generated_text?.stringValue || 
                    fields?.text?.stringValue || 
                    fields?.response?.stringValue;
    } else if (prediction.stringValue) {
      // Format texte simple
      responseText = prediction.stringValue;
    } else if (typeof prediction === 'string') {
      // R√©ponse directe en string
      responseText = prediction;
    }
    
    if (!responseText) {
      // Fallback : convertir l'objet en string pour debug
      responseText = JSON.stringify(prediction);
      console.log('Format de r√©ponse non reconnu, contenu brut:', prediction);
    }

    console.log('Texte de r√©ponse re√ßu:', responseText.substring(0, 200) + '...');

    // Essayer d'analyser la r√©ponse comme JSON, sinon cr√©er une structure par d√©faut
    let analysisResult;
    try {
      // Nettoyer le texte pour extraire le JSON si pr√©sent
      const jsonMatch = responseText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        analysisResult = JSON.parse(jsonMatch[0]);
      } else {
        throw new Error('Pas de JSON trouv√©');
      }
    } catch (parseError) {
      console.log('Erreur de parsing JSON, cr√©ation d\'une structure par d√©faut');
      // Cr√©er une analyse structur√©e √† partir du texte brut
      analysisResult = {
        hypothesis: extractMainDiagnosis(responseText) || "Analyse des images m√©dicales",
        confidence: 85,
        observations: extractObservations(responseText),
        severity: "medium",
        recommendations: extractRecommendations(responseText),
        fullReport: responseText
      };
    }

    // Valider et compl√©ter la structure de r√©ponse
    const validatedResult = {
      hypothesis: analysisResult.hypothesis || "Analyse en cours",
      confidence: Math.min(100, Math.max(0, analysisResult.confidence || 85)),
      observations: Array.isArray(analysisResult.observations) ? 
        analysisResult.observations : 
        extractObservations(responseText),
      severity: ["low", "medium", "high"].includes(analysisResult.severity) ? 
        analysisResult.severity : "medium",
      recommendations: Array.isArray(analysisResult.recommendations) ? 
        analysisResult.recommendations : 
        extractRecommendations(responseText),
      fullReport: analysisResult.fullReport || responseText
    };

    console.log('Analyse termin√©e avec succ√®s');
    res.json({ success: true, analysis: validatedResult });

  } catch (error) {
    console.error('Erreur lors de l\'analyse:', error);
    res.status(500).json({ 
      success: false, 
      error: error.message,
      details: error.stack 
    });
  }
});

// Fonctions utilitaires pour extraire des informations du texte
function extractMainDiagnosis(text) {
  const patterns = [
    /(?:diagnostic|hypoth√®se|conclusion)[^:]*:?\s*([^.\n]+)/i,
    /(?:suspicion|√©vocation)\s+d?[''']?([^.\n]+)/i,
    /^([^.\n]+)(?:\s+est|sont)?\s+(?:√©voqu√©|suspect√©|probable)/im
  ];
  
  for (const pattern of patterns) {
    const match = text.match(pattern);
    if (match && match[1]) {
      return match[1].trim();
    }
  }
  return null;
}

function extractObservations(text) {
  const observations = [];
  const lines = text.split('\n');
  
  for (const line of lines) {
    const trimmedLine = line.trim();
    if (trimmedLine.match(/^[-‚Ä¢*]\s+/) || 
        trimmedLine.match(/^\d+[\.)]\s+/) ||
        trimmedLine.includes('observ') ||
        trimmedLine.includes('visible') ||
        trimmedLine.includes('pr√©sence') ||
        trimmedLine.includes('absence')) {
      observations.push(trimmedLine.replace(/^[-‚Ä¢*\d\.)]\s*/, ''));
    }
  }
  
  return observations.length > 0 ? observations : [
    "Analyse de l'imagerie m√©dicale en cours",
    "√âvaluation des structures anatomiques",
    "Recherche d'anomalies pathologiques"
  ];
}

function extractRecommendations(text) {
  const recommendations = [];
  const lines = text.split('\n');
  
  for (const line of lines) {
    const trimmedLine = line.trim();
    if (trimmedLine.includes('recommand') ||
        trimmedLine.includes('conseill') ||
        trimmedLine.includes('sugg√®re') ||
        trimmedLine.includes('IRM') ||
        trimmedLine.includes('contr√¥le') ||
        trimmedLine.includes('suivi')) {
      recommendations.push(trimmedLine);
    }
  }
  
  return recommendations.length > 0 ? recommendations : [
    "Corr√©lation clinico-radiologique recommand√©e",
    "Suivi selon protocole √©tabli"
  ];
}

// Route de test pour v√©rifier la connexion
app.get('/api/health', (req, res) => {
  res.json({ 
    status: 'OK', 
    timestamp: new Date().toISOString(),
    medgemma: {
      projectId: projectId || 'Not configured',
      location: location,
      endpointId: endpointId || 'Not configured',
      modelId: modelId,
      dedicatedEndpoint: `${endpointId}.${location}-${projectId}.prediction.vertexai.goog`,
      developmentMode: isDevelopmentMode,
      clientConfigured: !!predictionServiceClient
    }
  });
});

// Route pour tester sans images
app.post('/api/test-analysis', async (req, res) => {
  try {
    const { clinicalContext } = req.body;
    
    // Simulation d'une analyse r√©ussie pour les tests
    const mockAnalysis = {
      hypothesis: "Test d'analyse r√©ussi",
      confidence: 90,
      observations: [
        "Connexion Vertex AI fonctionnelle",
        "Mod√®le MedGemma accessible",
        "Traitement des donn√©es op√©rationnel"
      ],
      severity: "low",
      recommendations: [
        "Syst√®me pr√™t pour l'analyse d'images",
        "Configuration Vertex AI valid√©e"
      ],
      fullReport: `TEST MEDGEMMA - ${new Date().toISOString()}\n\nContexte: ${clinicalContext}\n\nLe syst√®me est op√©rationnel et pr√™t √† traiter les analyses d'imagerie m√©dicale.`
    };

    res.json({ success: true, analysis: mockAnalysis });
  } catch (error) {
    res.status(500).json({ success: false, error: error.message });
  }
});

app.listen(port, () => {
  console.log(`üöÄ Backend MedGemma d√©marr√© sur le port ${port}`);
  console.log(`üìä Health check: http://localhost:${port}/api/health`);
  console.log(`üß† Configuration MedGemma:`);
  console.log(`   Project ID: ${projectId || 'Non configur√©'}`);
  console.log(`   Location: ${location}`);
  console.log(`   Endpoint ID: ${endpointId || 'Non configur√©'}`);
  console.log(`   Model: ${modelId}`);
  console.log(`   Endpoint URL: ${endpointId}.${location}-${projectId}.prediction.vertexai.goog`);
  
  if (isDevelopmentMode) {
    console.log(`üîß MODE D√âVELOPPEMENT ACTIV√â`);
    console.log(`   - Analyses simul√©es`);
    console.log(`   - Configurez votre cl√© Google Cloud pour l'analyse r√©elle`);
  } else if (!predictionServiceClient) {
    console.log(`‚ö†Ô∏è Client Vertex AI non configur√©`);
    console.log(`   - V√©rifiez votre cl√© de service Google Cloud`);
  } else {
    console.log(`‚úÖ Client Vertex AI configur√© et pr√™t`);
  }
});

module.exports = app;
